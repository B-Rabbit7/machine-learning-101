{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Standard Libraries Needed\n",
    "\n",
    "What will be covered:\n",
    "0. Scikit-Learn workflow\n",
    "1. Getting the data ready\n",
    "2. Choose the right estimator/algorithm for our problems\n",
    "3. Fir the model.algo and use it to make predictions on our data\n",
    "4. Evaluate the model\n",
    "5. Improve the model\n",
    "6. Save and load a trained model\n",
    "7. Put it all together"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Get the data ready"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n0     63    1   3       145   233    1        0      150      0      2.3   \n1     37    1   2       130   250    0        1      187      0      3.5   \n2     41    0   1       130   204    0        0      172      0      1.4   \n3     56    1   1       120   236    0        1      178      0      0.8   \n4     57    0   0       120   354    0        1      163      1      0.6   \n..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n298   57    0   0       140   241    0        1      123      1      0.2   \n299   45    1   3       110   264    0        1      132      0      1.2   \n300   68    1   0       144   193    1        1      141      0      3.4   \n301   57    1   0       130   131    0        1      115      1      1.2   \n302   57    0   1       130   236    0        0      174      0      0.0   \n\n     slope  ca  thal  target  \n0        0   0     1       1  \n1        0   0     2       1  \n2        2   0     2       1  \n3        2   0     2       1  \n4        2   0     2       1  \n..     ...  ..   ...     ...  \n298      1   0     3       0  \n299      1   0     3       0  \n300      1   2     3       0  \n301      1   1     3       0  \n302      1   1     2       0  \n\n[303 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>1</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>140</td>\n      <td>241</td>\n      <td>0</td>\n      <td>1</td>\n      <td>123</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>45</td>\n      <td>1</td>\n      <td>3</td>\n      <td>110</td>\n      <td>264</td>\n      <td>0</td>\n      <td>1</td>\n      <td>132</td>\n      <td>0</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>68</td>\n      <td>1</td>\n      <td>0</td>\n      <td>144</td>\n      <td>193</td>\n      <td>1</td>\n      <td>1</td>\n      <td>141</td>\n      <td>0</td>\n      <td>3.4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>130</td>\n      <td>131</td>\n      <td>0</td>\n      <td>1</td>\n      <td>115</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>57</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>236</td>\n      <td>0</td>\n      <td>0</td>\n      <td>174</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv(\"../matplotlib/heart-disease (1).csv\")\n",
    "heart_disease"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Create X (features matrix)\n",
    "X = heart_disease.drop(\"target\",axis=1)\n",
    "\n",
    "# Create Y (labels)\n",
    "Y = heart_disease[\"target\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Choose the right model and hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{'bootstrap': True,\n 'ccp_alpha': 0.0,\n 'class_weight': None,\n 'criterion': 'gini',\n 'max_depth': None,\n 'max_features': 'sqrt',\n 'max_leaf_nodes': None,\n 'max_samples': None,\n 'min_impurity_decrease': 0.0,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0,\n 'n_estimators': 100,\n 'n_jobs': None,\n 'oob_score': False,\n 'random_state': None,\n 'verbose': 0,\n 'warm_start': False}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "# We'll keep the default hyper parameters\n",
    "clf.get_params()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Fit the model to the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test,Y_train, Y_test, = train_test_split(X,Y,test_size=0.2) # 80% of the data will be used for training, 20% for testing\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "clf.fit(X_train, Y_train);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n       0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n       1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0], dtype=int64)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a prediction\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "y_preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Evaluate the model on the training data and the test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf.score(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7868852459016393"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.75        26\n",
      "           1       0.81      0.83      0.82        35\n",
      "\n",
      "    accuracy                           0.79        61\n",
      "   macro avg       0.78      0.78      0.78        61\n",
      "weighted avg       0.79      0.79      0.79        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(Y_test,y_preds))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[19,  7],\n       [ 6, 29]], dtype=int64)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test,y_preds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7868852459016393"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,y_preds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Improve a model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with 10, estimators\n",
      "Model accurancy on the test set: 81.97\n",
      "Trying model with 20, estimators\n",
      "Model accurancy on the test set: 78.69\n",
      "Trying model with 30, estimators\n",
      "Model accurancy on the test set: 77.05\n",
      "Trying model with 40, estimators\n",
      "Model accurancy on the test set: 78.69\n",
      "Trying model with 50, estimators\n",
      "Model accurancy on the test set: 77.05\n",
      "Trying model with 60, estimators\n",
      "Model accurancy on the test set: 78.69\n",
      "Trying model with 70, estimators\n",
      "Model accurancy on the test set: 77.05\n",
      "Trying model with 80, estimators\n",
      "Model accurancy on the test set: 73.77\n",
      "Trying model with 90, estimators\n",
      "Model accurancy on the test set: 77.05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Try different amount of n_estimators\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in range(10,100,10):\n",
    "    print(f\"Trying model with {i}, estimators\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(X_train,Y_train)\n",
    "    print(f\"Model accurancy on the test set: {clf.score(X_test,Y_test)*100:.2f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Save a model and load it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(clf,open(\"Random_forest_model_1.pkl\", \"wb\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"Random_forest_model_1.pkl\",\"rb\"))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7704918032786885"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.score(X_test,Y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Detailed Steps by Steps\n",
    "\n",
    "## 1. Getting our data ready to be used with ML\n",
    "\n",
    "There are three main things we need to do:\n",
    "    1. Split the data into features and labels (usually X & Y)\n",
    "    2. Filling (also called imputing) or disregarding missing values\n",
    "    3. Converting non-numerical values to numerical (feature encoding)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n0     63    1   3       145   233    1        0      150      0      2.3   \n1     37    1   2       130   250    0        1      187      0      3.5   \n2     41    0   1       130   204    0        0      172      0      1.4   \n3     56    1   1       120   236    0        1      178      0      0.8   \n4     57    0   0       120   354    0        1      163      1      0.6   \n..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n298   57    0   0       140   241    0        1      123      1      0.2   \n299   45    1   3       110   264    0        1      132      0      1.2   \n300   68    1   0       144   193    1        1      141      0      3.4   \n301   57    1   0       130   131    0        1      115      1      1.2   \n302   57    0   1       130   236    0        0      174      0      0.0   \n\n     slope  ca  thal  target  \n0        0   0     1       1  \n1        0   0     2       1  \n2        2   0     2       1  \n3        2   0     2       1  \n4        2   0     2       1  \n..     ...  ..   ...     ...  \n298      1   0     3       0  \n299      1   0     3       0  \n300      1   2     3       0  \n301      1   1     3       0  \n302      1   1     2       0  \n\n[303 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>1</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>140</td>\n      <td>241</td>\n      <td>0</td>\n      <td>1</td>\n      <td>123</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>45</td>\n      <td>1</td>\n      <td>3</td>\n      <td>110</td>\n      <td>264</td>\n      <td>0</td>\n      <td>1</td>\n      <td>132</td>\n      <td>0</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>68</td>\n      <td>1</td>\n      <td>0</td>\n      <td>144</td>\n      <td>193</td>\n      <td>1</td>\n      <td>1</td>\n      <td>141</td>\n      <td>0</td>\n      <td>3.4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>130</td>\n      <td>131</td>\n      <td>0</td>\n      <td>1</td>\n      <td>115</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>57</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>236</td>\n      <td>0</td>\n      <td>0</td>\n      <td>174</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n0   63    1   3       145   233    1        0      150      0      2.3      0   \n1   37    1   2       130   250    0        1      187      0      3.5      0   \n2   41    0   1       130   204    0        0      172      0      1.4      2   \n3   56    1   1       120   236    0        1      178      0      0.8      2   \n4   57    0   0       120   354    0        1      163      1      0.6      2   \n\n   ca  thal  \n0   0     1  \n1   0     2  \n2   0     2  \n3   0     2  \n4   0     2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>1</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "y = heart_disease[\"target\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "((242, 13), (61, 13), (242,), (61,))"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleaning data\n",
    "Clean data -> Transform Data -> Reduce Data\n",
    "\n",
    "Clean data = remove outliers / NAN values\n",
    "Transform data = convert string to numbers, convert color to numbers, yes or no is boolean, make sure the data is using the same metric system\n",
    "Reduce Data = more data, more cpu, reduce until we get the same result with either amount of data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Make sure it's all numerical"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "       Make Colour  Odometer (KM)  Doors  Price\n0     Honda  White          35431      4  15323\n1       BMW   Blue         192714      5  19943\n2     Honda  White          84714      4  28343\n3    Toyota  White         154365      4  13434\n4    Nissan   Blue         181577      3  14043\n..      ...    ...            ...    ...    ...\n995  Toyota  Black          35820      4  32042\n996  Nissan  White         155144      3   5716\n997  Nissan   Blue          66604      4  31570\n998   Honda  White         215883      4   4001\n999  Toyota   Blue         248360      4  12732\n\n[1000 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Make</th>\n      <th>Colour</th>\n      <th>Odometer (KM)</th>\n      <th>Doors</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Honda</td>\n      <td>White</td>\n      <td>35431</td>\n      <td>4</td>\n      <td>15323</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BMW</td>\n      <td>Blue</td>\n      <td>192714</td>\n      <td>5</td>\n      <td>19943</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Honda</td>\n      <td>White</td>\n      <td>84714</td>\n      <td>4</td>\n      <td>28343</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Toyota</td>\n      <td>White</td>\n      <td>154365</td>\n      <td>4</td>\n      <td>13434</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Nissan</td>\n      <td>Blue</td>\n      <td>181577</td>\n      <td>3</td>\n      <td>14043</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>Toyota</td>\n      <td>Black</td>\n      <td>35820</td>\n      <td>4</td>\n      <td>32042</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>Nissan</td>\n      <td>White</td>\n      <td>155144</td>\n      <td>3</td>\n      <td>5716</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>Nissan</td>\n      <td>Blue</td>\n      <td>66604</td>\n      <td>4</td>\n      <td>31570</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>Honda</td>\n      <td>White</td>\n      <td>215883</td>\n      <td>4</td>\n      <td>4001</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>Toyota</td>\n      <td>Blue</td>\n      <td>248360</td>\n      <td>4</td>\n      <td>12732</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales = pd.read_csv(\"car-sales-extended.csv\")\n",
    "car_sales"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "1000"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(car_sales)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "Make             object\nColour           object\nOdometer (KM)     int64\nDoors             int64\nPrice             int64\ndtype: object"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "# Split into trainig\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Toyota'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_28792\\4064751566.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m# use regressor for predicting number\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensemble\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mRandomForestRegressor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mRandomForestRegressor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    341\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    342\u001B[0m         \u001B[1;31m# Validate or convert input data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    343\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0missparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    344\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 345\u001B[1;33m         X, y = self._validate_data(\n\u001B[0m\u001B[0;32m    346\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmulti_output\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"csc\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mDTYPE\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    347\u001B[0m         )\n\u001B[0;32m    348\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0msample_weight\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    580\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[1;34m\"estimator\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcheck_y_params\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    581\u001B[0m                     \u001B[0mcheck_y_params\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mdefault_check_params\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    582\u001B[0m                 \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"y\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    583\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 584\u001B[1;33m                 \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    585\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    586\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    587\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mcheck_params\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"ensure_2d\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1102\u001B[0m         raise ValueError(\n\u001B[0;32m   1103\u001B[0m             \u001B[1;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         )\n\u001B[0;32m   1105\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1106\u001B[1;33m     X = check_array(\n\u001B[0m\u001B[0;32m   1107\u001B[0m         \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1108\u001B[0m         \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1109\u001B[0m         \u001B[0maccept_large_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_large_sparse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    876\u001B[0m                         )\n\u001B[0;32m    877\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    878\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    879\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_asarray_with_order\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mxp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 880\u001B[1;33m             \u001B[1;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    881\u001B[0m                 raise ValueError(\n\u001B[0;32m    882\u001B[0m                     \u001B[1;34m\"Complex data not supported\\n{}\\n\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    883\u001B[0m                 ) from complex_warning\n",
      "\u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(array, dtype, order, copy, xp)\u001B[0m\n\u001B[0;32m    181\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mxp\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    182\u001B[0m         \u001B[0mxp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_namespace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    183\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m\"numpy\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"numpy.array_api\"\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    184\u001B[0m         \u001B[1;31m# Use NumPy API to support order\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 185\u001B[1;33m         \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    186\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    187\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    188\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m   1996\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__array__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnpt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDTypeLike\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1997\u001B[0m         \u001B[0mvalues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1998\u001B[1;33m         \u001B[0marr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1999\u001B[0m         if (\n\u001B[0;32m   2000\u001B[0m             \u001B[0mastype_is_view\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2001\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0musing_copy_on_write\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'Toyota'"
     ]
    }
   ],
   "source": [
    "# Build machine learning model\n",
    "# use regressor for predicting number\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train,X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n        0.00000e+00, 3.54310e+04],\n       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n        1.00000e+00, 1.92714e+05],\n       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n        0.00000e+00, 8.47140e+04],\n       ...,\n       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 1.00000e+00,\n        0.00000e+00, 6.66040e+04],\n       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n        0.00000e+00, 2.15883e+05],\n       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n        0.00000e+00, 2.48360e+05]])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Why doors?\n",
    "##  It's numerical, but also categorical so we treat it as categorical\n",
    "categorical_features = [\"Make\",\"Colour\",\"Doors\"]\n",
    "# one for true in a category, 0 for the rest\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# transform the given cat. columns, and pass through - don't touch the remaining columns\n",
    "transformer = ColumnTransformer([(\"one_hot\",one_hot,categorical_features)],remainder=\"passthrough\")\n",
    "\n",
    "# transform the X values to numbers\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "      0    1    2    3    4    5    6    7    8    9    10   11        12\n0    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   35431.0\n1    1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  192714.0\n2    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   84714.0\n3    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  154365.0\n4    0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  181577.0\n..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...\n995  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   35820.0\n996  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  155144.0\n997  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0   66604.0\n998  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  215883.0\n999  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  248360.0\n\n[1000 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>35431.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>192714.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>84714.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>154365.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>181577.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>35820.0</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>155144.0</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>66604.0</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>215883.0</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>248360.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 13 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# Let's refit the model\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,y,train_size=0.2)\n",
    "\n",
    "model.fit(X_train,y_train);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "0.26160452087764263"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model hasn't really been able to find good patterns\n",
    "model.score(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What if there were missing values\n",
    "1. Fill it with some value(aka imputation)\n",
    "2. Remove the samples with missing data altogether"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "     Make Colour  Odometer (KM)  Doors    Price\n0   Honda  White        35431.0    4.0  15323.0\n1     BMW   Blue       192714.0    5.0  19943.0\n2   Honda  White        84714.0    4.0  28343.0\n3  Toyota  White       154365.0    4.0  13434.0\n4  Nissan   Blue       181577.0    3.0  14043.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Make</th>\n      <th>Colour</th>\n      <th>Odometer (KM)</th>\n      <th>Doors</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Honda</td>\n      <td>White</td>\n      <td>35431.0</td>\n      <td>4.0</td>\n      <td>15323.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BMW</td>\n      <td>Blue</td>\n      <td>192714.0</td>\n      <td>5.0</td>\n      <td>19943.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Honda</td>\n      <td>White</td>\n      <td>84714.0</td>\n      <td>4.0</td>\n      <td>28343.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Toyota</td>\n      <td>White</td>\n      <td>154365.0</td>\n      <td>4.0</td>\n      <td>13434.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Nissan</td>\n      <td>Blue</td>\n      <td>181577.0</td>\n      <td>3.0</td>\n      <td>14043.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "       Make Colour  Odometer (KM)  Doors    Price\n0     Honda  White        35431.0    4.0  15323.0\n1       BMW   Blue       192714.0    5.0  19943.0\n2     Honda  White        84714.0    4.0  28343.0\n3    Toyota  White       154365.0    4.0  13434.0\n4    Nissan   Blue       181577.0    3.0  14043.0\n..      ...    ...            ...    ...      ...\n995  Toyota  Black        35820.0    4.0  32042.0\n996     NaN  White       155144.0    3.0   5716.0\n997  Nissan   Blue        66604.0    4.0  31570.0\n998   Honda  White       215883.0    4.0   4001.0\n999  Toyota   Blue       248360.0    4.0  12732.0\n\n[1000 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Make</th>\n      <th>Colour</th>\n      <th>Odometer (KM)</th>\n      <th>Doors</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Honda</td>\n      <td>White</td>\n      <td>35431.0</td>\n      <td>4.0</td>\n      <td>15323.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BMW</td>\n      <td>Blue</td>\n      <td>192714.0</td>\n      <td>5.0</td>\n      <td>19943.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Honda</td>\n      <td>White</td>\n      <td>84714.0</td>\n      <td>4.0</td>\n      <td>28343.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Toyota</td>\n      <td>White</td>\n      <td>154365.0</td>\n      <td>4.0</td>\n      <td>13434.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Nissan</td>\n      <td>Blue</td>\n      <td>181577.0</td>\n      <td>3.0</td>\n      <td>14043.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>Toyota</td>\n      <td>Black</td>\n      <td>35820.0</td>\n      <td>4.0</td>\n      <td>32042.0</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>NaN</td>\n      <td>White</td>\n      <td>155144.0</td>\n      <td>3.0</td>\n      <td>5716.0</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>Nissan</td>\n      <td>Blue</td>\n      <td>66604.0</td>\n      <td>4.0</td>\n      <td>31570.0</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>Honda</td>\n      <td>White</td>\n      <td>215883.0</td>\n      <td>4.0</td>\n      <td>4001.0</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>Toyota</td>\n      <td>Blue</td>\n      <td>248360.0</td>\n      <td>4.0</td>\n      <td>12732.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'BMW'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_28792\\1327411735.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;31m## pick model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mRandomForestRegressor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;31m## get the model to learn and find pattern\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m \u001B[1;31m## test how well it's learnt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscore\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    341\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    342\u001B[0m         \u001B[1;31m# Validate or convert input data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    343\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0missparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    344\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 345\u001B[1;33m         X, y = self._validate_data(\n\u001B[0m\u001B[0;32m    346\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmulti_output\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"csc\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mDTYPE\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    347\u001B[0m         )\n\u001B[0;32m    348\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0msample_weight\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    580\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[1;34m\"estimator\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcheck_y_params\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    581\u001B[0m                     \u001B[0mcheck_y_params\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mdefault_check_params\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    582\u001B[0m                 \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"y\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    583\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 584\u001B[1;33m                 \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    585\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    586\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    587\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mcheck_params\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"ensure_2d\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1102\u001B[0m         raise ValueError(\n\u001B[0;32m   1103\u001B[0m             \u001B[1;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         )\n\u001B[0;32m   1105\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1106\u001B[1;33m     X = check_array(\n\u001B[0m\u001B[0;32m   1107\u001B[0m         \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1108\u001B[0m         \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1109\u001B[0m         \u001B[0maccept_large_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_large_sparse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    876\u001B[0m                         )\n\u001B[0;32m    877\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    878\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    879\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_asarray_with_order\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mxp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 880\u001B[1;33m             \u001B[1;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    881\u001B[0m                 raise ValueError(\n\u001B[0;32m    882\u001B[0m                     \u001B[1;34m\"Complex data not supported\\n{}\\n\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    883\u001B[0m                 ) from complex_warning\n",
      "\u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(array, dtype, order, copy, xp)\u001B[0m\n\u001B[0;32m    181\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mxp\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    182\u001B[0m         \u001B[0mxp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_namespace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    183\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m\"numpy\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"numpy.array_api\"\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    184\u001B[0m         \u001B[1;31m# Use NumPy API to support order\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 185\u001B[1;33m         \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    186\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    187\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    188\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m   1996\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__array__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnpt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDTypeLike\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1997\u001B[0m         \u001B[0mvalues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1998\u001B[1;33m         \u001B[0marr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1999\u001B[0m         if (\n\u001B[0;32m   2000\u001B[0m             \u001B[0mastype_is_view\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2001\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0musing_copy_on_write\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'BMW'"
     ]
    }
   ],
   "source": [
    "## Make data\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]\n",
    "\n",
    "## Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2)\n",
    "\n",
    "## pick model\n",
    "model = RandomForestRegressor()\n",
    "## get the model to learn and find pattern\n",
    "model.fit(X_train,y_train)\n",
    "## test how well it's learnt\n",
    "model.score(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 17\u001B[0m\n\u001B[0;32m     15\u001B[0m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mseed(\u001B[38;5;241m52\u001B[39m)\n\u001B[0;32m     16\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(transformed_X, y, train_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m)\n\u001B[1;32m---> 17\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m model\u001B[38;5;241m.\u001B[39mscore(X_test,y_test)\n",
      "File \u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(y):\n\u001B[0;32m    344\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse multilabel-indicator for y is not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 345\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\n\u001B[0;32m    347\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    349\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\base.py:584\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    582\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[0;32m    583\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 584\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    585\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    587\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1101\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[0;32m   1102\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1103\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1104\u001B[0m     )\n\u001B[1;32m-> 1106\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1108\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1109\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1111\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1113\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1114\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1118\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1119\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1120\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1122\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[0;32m   1124\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:845\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    843\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sp\u001B[38;5;241m.\u001B[39missparse(array):\n\u001B[0;32m    844\u001B[0m     _ensure_no_complex_data(array)\n\u001B[1;32m--> 845\u001B[0m     array \u001B[38;5;241m=\u001B[39m \u001B[43m_ensure_sparse_format\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    846\u001B[0m \u001B[43m        \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    848\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    849\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    850\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    851\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    852\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    853\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    854\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    855\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    856\u001B[0m     \u001B[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001B[39;00m\n\u001B[0;32m    857\u001B[0m     \u001B[38;5;66;03m# to an error. This is needed because specifying a non complex\u001B[39;00m\n\u001B[0;32m    858\u001B[0m     \u001B[38;5;66;03m# dtype to the function converts complex to real dtype,\u001B[39;00m\n\u001B[0;32m    859\u001B[0m     \u001B[38;5;66;03m# thereby passing the test made in the lines following the scope\u001B[39;00m\n\u001B[0;32m    860\u001B[0m     \u001B[38;5;66;03m# of warnings context manager.\u001B[39;00m\n\u001B[0;32m    861\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mcatch_warnings():\n",
      "File \u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:561\u001B[0m, in \u001B[0;36m_ensure_sparse_format\u001B[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    556\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    557\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt check \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m sparse matrix for nan or inf.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m spmatrix\u001B[38;5;241m.\u001B[39mformat,\n\u001B[0;32m    558\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m    559\u001B[0m         )\n\u001B[0;32m    560\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 561\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    562\u001B[0m \u001B[43m            \u001B[49m\u001B[43mspmatrix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    563\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    564\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    565\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    566\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m spmatrix\n",
      "File \u001B[1;32m~\\PycharmProjects\\machine-learning-101\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:161\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[0;32m    147\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    148\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    149\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    160\u001B[0m     )\n\u001B[1;32m--> 161\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[1;31mValueError\u001B[0m: Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "## determine the categorical features\n",
    "categorical_features = [\"Make\",\"Colour\",\"Doors\"]\n",
    "\n",
    "## create one hot encoder\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "## create column transformer\n",
    "transformer = ColumnTransformer([(\"one_hot\",one_hot,categorical_features)], remainder=\"passthrough\")\n",
    "\n",
    "## fit the transformer to X\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "\n",
    "## refit for the model\n",
    "\n",
    "np.random.seed(52)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, train_size=0.2)\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Option 1: Fill missing data with Pandas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "950"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fill the Make column\n",
    "car_sales_missing[\"Make\"].fillna(\"missing\",inplace=True)\n",
    "\n",
    "## Fill the Colour column\n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\",inplace=True)\n",
    "\n",
    "## Fill the Ode column\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(),inplace=True)\n",
    "\n",
    "## Fill the Doors column - category\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace=True)\n",
    "\n",
    "## Remove price with missing price value, its bad to predict based on missing lables\n",
    "car_sales_missing.dropna(inplace=True)\n",
    "\n",
    "\n",
    "len(car_sales_missing)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "0.09221717582096511"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make data\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]\n",
    "\n",
    "## determine the categorical features\n",
    "categorical_features = [\"Make\",\"Colour\",\"Doors\"]\n",
    "\n",
    "## create one hot encoder\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "## create column transformer\n",
    "transformer = ColumnTransformer([(\"one_hot\",one_hot,categorical_features)], remainder=\"passthrough\")\n",
    "\n",
    "## fit the transformer to X\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "\n",
    "## refit for the model\n",
    "\n",
    "np.random.seed(52)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, train_size=0.2)\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "950"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(car_sales_missing)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Option 2: Fill missing values with Sickit-Learn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Important:\n",
    "Fill the training and testing data seperately no matter the technique used to fill the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "       Make Colour  Odometer (KM)  Doors    Price\n0     Honda  White        35431.0    4.0  15323.0\n1       BMW   Blue       192714.0    5.0  19943.0\n2     Honda  White        84714.0    4.0  28343.0\n3    Toyota  White       154365.0    4.0  13434.0\n4    Nissan   Blue       181577.0    3.0  14043.0\n..      ...    ...            ...    ...      ...\n995  Toyota  Black        35820.0    4.0  32042.0\n996     NaN  White       155144.0    3.0   5716.0\n997  Nissan   Blue        66604.0    4.0  31570.0\n998   Honda  White       215883.0    4.0   4001.0\n999  Toyota   Blue       248360.0    4.0  12732.0\n\n[1000 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Make</th>\n      <th>Colour</th>\n      <th>Odometer (KM)</th>\n      <th>Doors</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Honda</td>\n      <td>White</td>\n      <td>35431.0</td>\n      <td>4.0</td>\n      <td>15323.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BMW</td>\n      <td>Blue</td>\n      <td>192714.0</td>\n      <td>5.0</td>\n      <td>19943.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Honda</td>\n      <td>White</td>\n      <td>84714.0</td>\n      <td>4.0</td>\n      <td>28343.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Toyota</td>\n      <td>White</td>\n      <td>154365.0</td>\n      <td>4.0</td>\n      <td>13434.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Nissan</td>\n      <td>Blue</td>\n      <td>181577.0</td>\n      <td>3.0</td>\n      <td>14043.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>Toyota</td>\n      <td>Black</td>\n      <td>35820.0</td>\n      <td>4.0</td>\n      <td>32042.0</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>NaN</td>\n      <td>White</td>\n      <td>155144.0</td>\n      <td>3.0</td>\n      <td>5716.0</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>Nissan</td>\n      <td>Blue</td>\n      <td>66604.0</td>\n      <td>4.0</td>\n      <td>31570.0</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>Honda</td>\n      <td>White</td>\n      <td>215883.0</td>\n      <td>4.0</td>\n      <td>4001.0</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>Toyota</td>\n      <td>Blue</td>\n      <td>248360.0</td>\n      <td>4.0</td>\n      <td>12732.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "Make             47\nColour           46\nOdometer (KM)    48\nDoors            47\nPrice             0\ndtype: int64"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the rows with no labels\n",
    "car_sales_missing.dropna(subset=[\"Price\"],inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# Split into X and Y\n",
    "\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['Honda', 'White', 4.0, 35431.0],\n       ['BMW', 'Blue', 5.0, 192714.0],\n       ['Honda', 'White', 4.0, 84714.0],\n       ...,\n       ['Nissan', 'Blue', 4.0, 66604.0],\n       ['Honda', 'White', 4.0, 215883.0],\n       ['Toyota', 'Blue', 4.0, 248360.0]], dtype=object)"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing valys with Scikit-Learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Fill categorical values with missing, and numerical with mean\n",
    "# if strategy is constant, we need to suggest the fill value\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Define Columns\n",
    "cat_features = [\"Make\",\"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "num_feature = [\"Odometer (KM)\"]\n",
    "\n",
    "# Create an imputer (something that goes in and fills the missing data accordingly)\n",
    "# the tuples are the tranformations we want it to make, params are : name of imputer, imputer, imputee\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer,cat_features),\n",
    "    (\"door_imputer\", door_imputer,door_feature),\n",
    "    (\"num_imputer\",num_imputer,num_feature)\n",
    "])\n",
    "\n",
    "# Transform the data\n",
    "\n",
    "filled_X = imputer.fit_transform(X)\n",
    "filled_X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "Make             0\nColour           0\nDoors            0\nOdometer (KM)    0\ndtype: int64"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_filled = pd.DataFrame(filled_X,columns=[\"Make\",\"Colour\",\"Doors\",\"Odometer (KM)\"])\n",
    "car_sales_filled.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "<950x15 sparse matrix of type '<class 'numpy.float64'>'\n\twith 3800 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Why doors?\n",
    "##  It's numerical, but also categorical so we treat it as categorical\n",
    "categorical_features = [\"Make\",\"Colour\",\"Doors\"]\n",
    "# one for true in a category, 0 for the rest\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# transform the given cat. columns, and pass through - don't touch the remaining columns\n",
    "transformer = ColumnTransformer([(\"one_hot\",one_hot,categorical_features)],remainder=\"passthrough\")\n",
    "\n",
    "# transform the X values to numbers\n",
    "transformed_X = transformer.fit_transform(car_sales_filled)\n",
    "transformed_X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "0.19202325589865898"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we've got the data as numbers and filled the missing values\n",
    "# Lets fit the model\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,y,train_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=1000)\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Choosing the right"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
